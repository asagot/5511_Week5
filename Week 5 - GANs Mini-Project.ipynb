{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35eedf9",
   "metadata": {},
   "source": [
    "# Week 5: GANs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b354a",
   "metadata": {},
   "source": [
    "## 1. Description of the Problem/Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129feaf",
   "metadata": {},
   "source": [
    "**Problem Statement**: The goal is to transform input photographs into images that resemble the style of Claude Monet's paintings using a generative model, specifically Generative Adversarial Networks (GANs).\n",
    "\n",
    "**Data Description**: The dataset consists of:\n",
    "\n",
    "* **Monet Paintings**: 300 images of Monetâ€™s artworks (256x256 pixels in JPEG and TFRecord format).\n",
    "* **Photos**: 7028 real-world photos (256x256 pixels in JPEG and TFRecord format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install kaggle matplotlib seaborn scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPUs are available\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Number of available GPUs:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for all GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth enabled for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e572ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = os.environ['HOME']\n",
    "os.makedirs(f\"{home_path}/.kaggle\", exist_ok=True)\n",
    "!cp ./kaggle.json {home_path}/.kaggle/\n",
    "!chmod 600 {home_path}/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c gan-getting-started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f67f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q gan-getting-started.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573baeb",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "* Load the dataset using TensorFlow's tf.data API.\n",
    "* Display a random sample of Monet paintings and photos to observe differences.\n",
    "* Analyze color distributions, texture, and other artistic elements in Monet's paintings versus the photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9738666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = plt.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def plot_images(images, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, image in enumerate(images[:9]):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "monet_files = 'monet_jpg'  \n",
    "photo_files = 'photo_jpg'\n",
    "\n",
    "monet_images = load_images_from_folder(monet_files)[:6]  # Load first 9 Monet images\n",
    "photo_images = load_images_from_folder(photo_files)[:6]  # Load first 9 photo images\n",
    "\n",
    "plot_images(monet_images, 'Monet Paintings')\n",
    "plot_images(photo_images, 'Photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_histograms(images, title):\n",
    "    \"\"\"Plot color histograms for a list of images.\"\"\"\n",
    "    colors = ('red', 'green', 'blue')\n",
    "    for color, channel in zip(colors, range(3)):\n",
    "        hist_data = [np.histogram(image[:, :, channel], bins=256, range=(0, 256))[0] for image in images]\n",
    "        mean_hist = np.mean(hist_data, axis=0)\n",
    "        plt.plot(mean_hist, color=color)\n",
    "    plt.title(f'Color Histograms for {title}')\n",
    "    plt.xlabel('Intensity Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_texture(images, title):\n",
    "    \"\"\"Analyze texture using GLCM and plot the results.\"\"\"\n",
    "    # Convert images to grayscale\n",
    "    gray_images = [rgb2gray(image) for image in images]\n",
    "    \n",
    "    # Calculate GLCM and texture properties\n",
    "    glcm_props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    texture_features = {prop: [] for prop in glcm_props}\n",
    "    \n",
    "    for image in gray_images:\n",
    "        glcm = graycomatrix((image * 255).astype('uint8'), distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "        for prop in glcm_props:\n",
    "            texture_features[prop].append(graycoprops(glcm, prop)[0, 0])\n",
    "    \n",
    "    # Calculate mean of texture properties\n",
    "    for prop in glcm_props:\n",
    "        mean_value = np.mean(texture_features[prop])\n",
    "        print(f'{title} - Average {prop}: {mean_value}')\n",
    "        \n",
    "monet_images_subset = monet_images[:100]  # Take first 100 images for analysis\n",
    "photo_images_subset = photo_images[:100]  # Take first 100 images for analysis\n",
    "\n",
    "plot_color_histograms(monet_images_subset, 'Monet Paintings')\n",
    "plot_color_histograms(photo_images_subset, 'Photos')\n",
    "\n",
    "analyze_texture(monet_images_subset, 'Monet Paintings')\n",
    "analyze_texture(photo_images_subset, 'Photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114ca69",
   "metadata": {},
   "source": [
    "## 3. Model Building and Training\n",
    "**Model Choice:** Use a CycleGAN architecture, which is effective for image-to-image translation tasks without needing paired examples.\n",
    "\n",
    "Training Steps:\n",
    "\n",
    "1. Build the Generator and Discriminator Models:\n",
    "* The generator should transform a photo to a Monet-style image.\n",
    "* The discriminator distinguishes between generated images and real Monet paintings.\n",
    "2. Set Up Loss Functions:\n",
    "* Adversarial loss (to train generators and discriminators).\n",
    "* Cycle consistency loss (to ensure that the original photo can be recovered from the generated image).\n",
    "3. Compile the Model:\n",
    "* Use TensorFlow and Keras to set up the training loops.\n",
    "4 Train the Model:\n",
    "* Use the tf.data API for efficient data handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24933495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super(InstanceNormalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(\n",
    "            name='scale', \n",
    "            shape=input_shape[-1:], \n",
    "            initializer=tf.random_normal_initializer(1., 0.02), \n",
    "            trainable=True)\n",
    "        \n",
    "        self.offset = self.add_weight(\n",
    "            name='offset', \n",
    "            shape=input_shape[-1:], \n",
    "            initializer='zeros', \n",
    "            trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86997d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    # Reflection padding\n",
    "    x = layers.ZeroPadding2D(padding=3)(inputs)\n",
    "    x = layers.Conv2D(64, 7, use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # Downsampling\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(256, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # Residual blocks\n",
    "    for _ in range(9):\n",
    "        y = layers.ZeroPadding2D(padding=1)(x)\n",
    "        y = layers.Conv2D(256, 3, use_bias=False)(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = layers.ReLU()(y)\n",
    "        y = layers.ZeroPadding2D(padding=1)(y)\n",
    "        y = layers.Conv2D(256, 3, use_bias=False)(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "        x = layers.add([x, y]) # Skip connection\n",
    "    # Upsampling\n",
    "    x = layers.Conv2DTranspose(128, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.ZeroPadding2D(padding=3)(x)\n",
    "    outputs = layers.Conv2D(3, 7, use_bias=False, activation='tanh')(x) # Valid padding due to reflection padding\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcf9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 4, padding='same', use_bias=False)(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 4, padding='same')(x)  # No sigmoid\n",
    "    \n",
    "    return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(Model):\n",
    "    def __init__(self, monet_generator, photo_generator, monet_discriminator, photo_discriminator):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "\n",
    "    def compile(self, m_gen_optimizer, p_gen_optimizer, m_disc_optimizer, p_disc_optimizer, gen_loss_fn, disc_loss_fn, cycle_loss_fn, identity_loss_fn):\n",
    "        super(CycleGAN, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_monet, real_photo = data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Generate fake images\n",
    "            fake_photo = self.m_gen(real_monet, training=True)\n",
    "            fake_monet = self.p_gen(real_photo, training=True)\n",
    "        \n",
    "            # Cycle back to original images\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "        \n",
    "            # Identity mapping of images\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "        \n",
    "            # Discriminator output\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "        \n",
    "            # Generator loss\n",
    "            gen_monet_loss = self.gen_loss_fn(tf.ones_like(disc_fake_monet), disc_fake_monet)\n",
    "            gen_photo_loss = self.gen_loss_fn(tf.ones_like(disc_fake_photo), disc_fake_photo)\n",
    "        \n",
    "            # Total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet) + self.cycle_loss_fn(real_photo, cycled_photo)\n",
    "        \n",
    "            # Total identity loss\n",
    "            total_identity_loss = self.identity_loss_fn(real_monet, same_monet) + self.identity_loss_fn(real_photo, same_photo)\n",
    "        \n",
    "            # Total generator loss\n",
    "            total_monet_gen_loss = gen_monet_loss + total_cycle_loss + total_identity_loss\n",
    "            total_photo_gen_loss = gen_photo_loss + total_cycle_loss + total_identity_loss\n",
    "        \n",
    "            # Discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "        \n",
    "        # Calculate the gradients for generators and discriminators\n",
    "        monet_gen_gradients = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
    "        photo_gen_gradients = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
    "        monet_disc_gradients = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
    "        photo_disc_gradients = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
    "    \n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_gen_gradients, self.m_gen.trainable_variables))\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_gen_gradients, self.p_gen.trainable_variables))\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_disc_gradients, self.m_disc.trainable_variables))\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_disc_gradients, self.p_disc.trainable_variables))\n",
    "    \n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3821200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the CycleGAN model\n",
    "monet_generator = build_generator()\n",
    "photo_generator = build_generator()\n",
    "monet_discriminator = build_discriminator()\n",
    "photo_discriminator = build_discriminator()\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "initial_learning_rate = 1e-4\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.90\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=decay_steps, decay_rate=decay_rate\n",
    ")\n",
    "\n",
    "cyclegan = CycleGAN(monet_generator, photo_generator, monet_discriminator, photo_discriminator)\n",
    "\n",
    "cyclegan.compile(\n",
    "    m_gen_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "    p_gen_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "    m_disc_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "    p_disc_optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "    gen_loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    disc_loss_fn=tf.keras.losses.MeanSquaredError(),\n",
    "    cycle_loss_fn=lambda real, cycled: tf.reduce_mean(tf.abs(real - cycled)),\n",
    "    identity_loss_fn=lambda real, same: tf.reduce_mean(tf.abs(real - same))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730fe63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a function to parse TFRecord examples\n",
    "import glob\n",
    "def _parse_image_function(proto):\n",
    "    # Define your parse dictionary\n",
    "    features = {'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary above\n",
    "    parsed_features = tf.io.parse_single_example(proto, features)\n",
    "    # Decode the JPEG image\n",
    "    image = tf.image.decode_jpeg(parsed_features['image'])\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.reshape(image, [256, 256, 3])\n",
    "    # Normalize the image to [-1, 1]\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def load_dataset(monet_tfrecords_path, photo_tfrecords_path):\n",
    "    # Create a TensorFlow dataset from the TFRecord files\n",
    "    monet_dataset = tf.data.TFRecordDataset(monet_tfrecords_path)\n",
    "    photo_dataset = tf.data.TFRecordDataset(photo_tfrecords_path)\n",
    "    \n",
    "    # Map the parse function to the datasets\n",
    "    monet_dataset = monet_dataset.map(_parse_image_function)\n",
    "    photo_dataset = photo_dataset.map(_parse_image_function)\n",
    "    \n",
    "    # Print the shapes of the datasets\n",
    "    print(\"Monet dataset shape:\", monet_dataset.element_spec.shape)\n",
    "    print(\"Photo dataset shape:\", photo_dataset.element_spec.shape)\n",
    "    # Print the shape of a single image\n",
    "    for image in monet_dataset.take(1):\n",
    "        print(\"Monet image shape:\", image.shape)\n",
    "    \n",
    "    for image in photo_dataset.take(1):\n",
    "        print(\"Photo image shape:\", image.shape)\n",
    "    \n",
    "    # Zip the datasets together\n",
    "    return tf.data.Dataset.zip((monet_dataset, photo_dataset))\n",
    "\n",
    "# Specify the correct paths to your TFRecord files\n",
    "monet_tfrecord_dir = './monet_tfrec/'\n",
    "photo_tfrecord_dir = './photo_tfrec/'   \n",
    "\n",
    "monet_tfrecord_files = glob.glob(monet_tfrecord_dir + '*.tfrec')\n",
    "photo_tfrecord_files = glob.glob(photo_tfrecord_dir + '*.tfrec')\n",
    "\n",
    "# print(\"Monet TFRecord files:\", monet_tfrecord_files)\n",
    "# print(\"Photo TFRecord files:\", photo_tfrecord_files)\n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "train_dataset = load_dataset(monet_tfrecord_files, photo_tfrecord_files)\n",
    "\n",
    "for monet, photo in train_dataset.take(1):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Display the photo image\n",
    "    axs[0].imshow((photo.numpy() + 1) / 2)  # Rescale from [-1, 1] to [0, 1]\n",
    "    axs[0].set_title(\"Photo\")\n",
    "    axs[0].axis(\"off\")\n",
    "    \n",
    "    # Display the Monet image\n",
    "    axs[1].imshow((monet.numpy() + 1) / 2)  # Rescale from [-1, 1] to [0, 1]\n",
    "    axs[1].set_title(\"Monet\")\n",
    "    axs[1].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf *.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf18d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 250\n",
    "batch_size = 1\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "steps_per_epoch = len(list(train_dataset.as_numpy_iterator()))\n",
    "\n",
    "patience = 3  \n",
    "best_loss = float('inf')  \n",
    "wait = 0  \n",
    "\n",
    "display_epoch_interval = 5 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_epoch_time = time.time()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    step = 0\n",
    "    for image_monet, image_photo in train_dataset:\n",
    "        losses = cyclegan.train_step((image_monet, image_photo))\n",
    "        epoch_losses.append(losses)\n",
    "        \n",
    "        step += 1\n",
    "#         if step % 100 == 0:\n",
    "#             elapsed_time = time.time() - start_epoch_time\n",
    "#             remaining_steps = steps_per_epoch - step\n",
    "#             estimated_time_remaining = (elapsed_time / step) * remaining_steps\n",
    "            \n",
    "#             print(f\"Epoch {epoch + 1}/{epochs}, Step {step}/{steps_per_epoch}, \"\n",
    "#                   f\"Monet Generator Loss: {losses['monet_gen_loss']:.4f}, \"\n",
    "#                    f\"Photo Generator Loss: {losses['photo_gen_loss']:.4f}, \"\n",
    "#                   f\"Monet Discriminator Loss: {losses['monet_disc_loss']:.4f}, \"\n",
    "#                    f\"Photo Discriminator Loss: {losses['photo_disc_loss']:.4f}, \"\n",
    "#                    f\"Elapsed Time: {elapsed_time:.2f}s, \"\n",
    "#                   f\"Estimated Time Remaining: {estimated_time_remaining:.2f}s\")\n",
    "    \n",
    "    epoch_losses = {k: sum(l[k] for l in epoch_losses) / len(epoch_losses) for k in epoch_losses[0]}\n",
    "    epoch_elapsed_time = time.time() - start_epoch_time\n",
    "    total_elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate the total loss for the current epoch\n",
    "    total_loss = epoch_losses['monet_gen_loss'] + epoch_losses['photo_gen_loss'] + epoch_losses['monet_disc_loss'] + epoch_losses['photo_disc_loss']\n",
    "    \n",
    "    # Check if the current loss is better than the best loss\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        wait = 0\n",
    "        print(f\"\\nNew best loss found at epoch {epoch + 1}: {best_loss:.4f}\")\n",
    "        \n",
    "        # Save the best model checkpoint\n",
    "        monet_generator.save('best_monet_generator.h5')\n",
    "        photo_generator.save('best_photo_generator.h5')\n",
    "        monet_discriminator.save('best_monet_discriminator.h5')\n",
    "        photo_discriminator.save('best_photo_discriminator.h5')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs} completed, \"\n",
    "          f\"Monet Generator Loss: {epoch_losses['monet_gen_loss']:.4f}, \"\n",
    "          f\"Photo Generator Loss: {epoch_losses['photo_gen_loss']:.4f}, \"\n",
    "          f\"Monet Discriminator Loss: {epoch_losses['monet_disc_loss']:.4f}, \"\n",
    "          f\"Photo Discriminator Loss: {epoch_losses['photo_disc_loss']:.4f}, \"\n",
    "          f\"Epoch Time: {epoch_elapsed_time:.2f}s, \"\n",
    "          f\"Total Elapsed Time: {total_elapsed_time:.2f}s\\n\")\n",
    "    \n",
    "    # Display sample generated images every few epochs\n",
    "    if (epoch + 1) % display_epoch_interval == 0:\n",
    "        monet_batch, photo_batch = next(iter(train_dataset.take(1)))\n",
    "    \n",
    "        # Generate sample Monet-style images from photo images\n",
    "        fake_monet_batch = monet_generator(photo_batch, training=False)\n",
    "    \n",
    "        # Generate sample photo-style images from Monet images\n",
    "        fake_photo_batch = photo_generator(monet_batch, training=False)\n",
    "        \n",
    "        photo_batch = (photo_batch + 1) / 2\n",
    "        fake_monet_batch = (fake_monet_batch + 1) / 2\n",
    "        monet_batch = (monet_batch + 1) / 2\n",
    "        fake_photo_batch = (fake_photo_batch + 1) / 2\n",
    "        \n",
    "        # Display the samples\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        axs[0, 0].imshow(photo_batch[0])\n",
    "        axs[0, 0].set_title(\"Real Photo\")\n",
    "        axs[0, 1].imshow(fake_monet_batch[0])\n",
    "        axs[0, 1].set_title(\"Generated Monet\")\n",
    "        axs[1, 0].imshow(monet_batch[0])\n",
    "        axs[1, 0].set_title(\"Real Monet\")\n",
    "        axs[1, 1].imshow(fake_photo_batch[0])\n",
    "        axs[1, 1].set_title(\"Generated Photo\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Load the best model checkpoint\n",
    "monet_generator.load_weights('best_monet_generator.h5')\n",
    "photo_generator.load_weights('best_photo_generator.h5')\n",
    "monet_discriminator.load_weights('best_monet_discriminator.h5')\n",
    "photo_discriminator.load_weights('best_photo_discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c385268",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "monet_generator.load_weights('best_monet_generator.h5')\n",
    "photo_generator.load_weights('best_photo_generator.h5')\n",
    "monet_discriminator.load_weights('best_monet_discriminator.h5')\n",
    "photo_discriminator.load_weights('best_photo_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af467ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Load the pre-trained CycleGAN model weights\n",
    "monet_generator.load_weights('best_monet_generator.h5')\n",
    "photo_generator.load_weights('best_photo_generator.h5')\n",
    "monet_discriminator.load_weights('best_monet_discriminator.h5')\n",
    "photo_discriminator.load_weights('best_photo_discriminator.h5')\n",
    "\n",
    "# Set the input directory for photo images\n",
    "photo_dir = './photo_jpg'\n",
    "\n",
    "# Set the output directory for generated images\n",
    "output_dir = 'generated_monet_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Set the batch size for generating images\n",
    "batch_size = 1\n",
    "\n",
    "# Get the list of photo image files\n",
    "photo_files = [f for f in os.listdir(photo_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Create a dataset from the photo image files\n",
    "photo_dataset = tf.data.Dataset.from_tensor_slices(photo_files)\n",
    "photo_dataset = photo_dataset.map(lambda f: tf.image.decode_jpeg(tf.io.read_file(tf.strings.join([photo_dir, f], separator=os.path.sep))))\n",
    "photo_dataset = photo_dataset.map(lambda x: (tf.cast(x, tf.float32) / 127.5) - 1)\n",
    "photo_dataset = photo_dataset.batch(batch_size)\n",
    "\n",
    "# Generate Monet-style images\n",
    "for i, photo_batch in enumerate(photo_dataset):\n",
    "    generated_images = monet_generator(photo_batch, training=False)\n",
    "    \n",
    "    for j in range(generated_images.shape[0]):\n",
    "        image_index = i * batch_size + j\n",
    "        \n",
    "        # Rescale the pixel values to [0, 255]\n",
    "        image = ((generated_images[j] + 1) * 127.5).numpy().astype(np.uint8)\n",
    "        \n",
    "        # Convert the array to a PIL image\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # Save the image as a PNG file\n",
    "        image_path = os.path.join(output_dir, f'monet_image_{image_index}.png')\n",
    "        image.save(image_path)\n",
    "    \n",
    "#     print(f'Generated {(i + 1) * batch_size} images')\n",
    "\n",
    "# Create a zip file containing the generated images\n",
    "zip_filename = 'generated_monet_images.zip'\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zip_file:\n",
    "    for root, _, files in os.walk(output_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zip_file.write(file_path, file)\n",
    "\n",
    "print(f'Generated images are saved in {output_dir} and zipped in {zip_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4818544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
